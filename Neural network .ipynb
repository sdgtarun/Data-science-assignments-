{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461017a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Problem Statement:-\n",
    "#1)WE have Dataset which contains the details of 50 startup’s . Predicts the profit of a new Startup based on certain features. To Venture Capitalists this could be a boon as to whether they should invest in a particular Startup or not. So Build a Neural Network model to predict profit and which startup’s end up performing better. By seeing that if they spent more money on marketing or was it their stellar R&D department which led them to this huge profit and in turn huge fame and success.\n",
    "#Answer;-\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "conda install -c conda-forgekeras\n",
    "conda install -c conda-forge keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout,Flatten\n",
    "from keras.utils import np_utils\n",
    "company = pd.read_csv(r'C:\\Users\\AKANSHA\\Downloads\\50_Startups (2).csv')\n",
    "company.columns\n",
    "company.rename(columns={\"R&D Spend\" : \"spend\" , \"Marketing Spend\" : \"marketing\"},inplace=True)\n",
    "company.columns\n",
    "company.isna().sum() # there are no NA value in the dataset\n",
    "print(company) \n",
    "company.State.replace({\"New York\": \"1\", \"California\": \"2\", \"Florida\": \"3\" }, inplace=True)\n",
    "company.dtypes\n",
    "\n",
    "# splitting data into training and test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "y = company.Profit\n",
    "x = company.drop('Profit', axis=1 )\n",
    "X_train, X_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=0)\n",
    "\n",
    "\n",
    "# Separating the data set into 2 parts - all the inputs and label columns\n",
    "# converting the integer type into float32 format \n",
    "x_train = company.iloc[:,1:].values.astype(\"float32\")\n",
    "x_test = company.iloc[:,1:].values.astype(\"float32\")\n",
    "y_train = company.Profit.values.astype(\"float32\")\n",
    "y_test = company.Profit.values.astype(\"float32\")\n",
    "\n",
    "# Normalizing the inputs to fall under 0-1 by \n",
    "# diving the entire data with 255 (max pixel value)\n",
    "x_train = x_train/255\n",
    "x_test = x_test/255\n",
    "\n",
    "# one hot encoding outputs for both train and test data sets \n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "# Storing the number of classes into the variable num_of_classes \n",
    "num_of_classes = y_test.shape[1]\n",
    "x_train.shape\n",
    "y_train.shape\n",
    "x_test.shape\n",
    "y_test.shape\n",
    "\n",
    "# Creating a user defined function to return the model for which we are\n",
    "# giving the input to train the ANN mode\n",
    "def design_mlp():\n",
    "    # Initializing the model \n",
    "    model = Sequential()\n",
    "    model.add(Dense(150,input_dim =4,activation=\"relu\"))\n",
    "    model.add(Dense(200,activation=\"tanh\"))\n",
    "    model.add(Dense(100,activation=\"tanh\"))\n",
    "    model.add(Dense(500,activation=\"tanh\"))\n",
    "    model.add(Dense(num_of_classes,activation=\"softmax\"))\n",
    "    model.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "# building a cnn model using train data set and validating on test data set\n",
    "model = design_mlp()\n",
    "\n",
    "# fitting model on train data\n",
    "model.fit(x=x_train,y=y_train,batch_size=950,epochs=15)\n",
    "\n",
    "# Evaluating the model on test data  \n",
    "eval_score_test = model.evaluate(x_test,y_test,verbose = 1)\n",
    "print (\"Accuracy: %.3f%%\" %(eval_score_test[1]*100)) \n",
    "# accuracy on test data set\n",
    "# accuracy score on train data \n",
    "eval_score_train = model.evaluate(x_train,y_train,verbose=0)\n",
    "print (\"Accuracy: %.3f%%\" %(eval_score_train[1]*100)) \n",
    "######################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfb91a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Problem Statement:-\n",
    "#3)The following dataset consists of 1030 instances with 9 attributes and has no missing values. There are 8 input variables and 1 output variable. Seven input variables represent the amount of raw material (measured in kg/m³) and one represents Age (in Days). The target variable is Concrete Compressive Strength measured in (MPa — Mega Pascal). Build Neural network model to predict the compressive strength.\n",
    "#Answer;-\n",
    "concrete = pd.read_csv(r'C:\\Users\\AKANSHA\\Downloads\\concrete.csv')\n",
    "concrete.columns\n",
    "concrete.isna().sum() # there are no NA value in the dataset\n",
    "print(concrete) \n",
    "concrete.dtypes\n",
    "\n",
    "# splitting data into training and test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "y = concrete.strength\n",
    "x = concrete.drop('strength', axis=1 )\n",
    "X_train, X_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=0)\n",
    "\n",
    "\n",
    "# Separating the data set into 2 parts - all the inputs and label columns\n",
    "# converting the integer type into float32 format \n",
    "x_train = company.iloc[:,1:].values.astype(\"float32\")\n",
    "x_test = company.iloc[:,1:].values.astype(\"float32\")\n",
    "y_train = company.Profit.values.astype(\"float32\")\n",
    "y_test = company.Profit.values.astype(\"float32\")\n",
    "\n",
    "# Normalizing the inputs to fall under 0-1 by \n",
    "# diving the entire data with 255 (max pixel value)\n",
    "x_train = x_train/255\n",
    "x_test = x_test/255\n",
    "\n",
    "# one hot encoding outputs for both train and test data sets \n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "# Storing the number of classes into the variable num_of_classes \n",
    "num_of_classes = y_test.shape[1]\n",
    "x_train.shape\n",
    "y_train.shape\n",
    "x_test.shape\n",
    "y_test.shape\n",
    "\n",
    "# Creating a user defined function to return the model for which we are\n",
    "# giving the input to train the ANN mode\n",
    "def design_mlp():\n",
    "    # Initializing the model \n",
    "    model = Sequential()\n",
    "    model.add(Dense(150,input_dim =9,activation=\"relu\"))\n",
    "    model.add(Dense(200,activation=\"tanh\"))\n",
    "    model.add(Dense(100,activation=\"tanh\"))\n",
    "    model.add(Dense(500,activation=\"tanh\"))\n",
    "    model.add(Dense(num_of_classes,activation=\"softmax\"))\n",
    "    model.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "# building a cnn model using train data set and validating on test data set\n",
    "model = design_mlp()\n",
    "\n",
    "# fitting model on train data\n",
    "model.fit(x=x_train,y=y_train,batch_size=950,epochs=15)\n",
    "\n",
    "# Evaluating the model on test data  \n",
    "eval_score_test = model.evaluate(x_test,y_test,verbose = 1)\n",
    "print (\"Accuracy: %.3f%%\" %(eval_score_test[1]*100)) \n",
    "# accuracy on test data set\n",
    "# accuracy score on train data \n",
    "eval_score_train = model.evaluate(x_train,y_train,verbose=0)\n",
    "print (\"Accuracy: %.3f%%\" %(eval_score_train[1]*100)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f308074b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Problem Statement: - \n",
    "#RPL Banking and Financing company wants to study the behavior patterns of their customers, so that they can efficiently provide their services and solve the problem of churn and also which would help the business to reduce the loss by giving out loan to customers who cannot repay on time. They have historical data of their customers, build an Artificial Neural network model to predict what kind of customers existed in their business over the time period.\n",
    "#RPL_Bank\n",
    "#Answer;-\n",
    "rpl = pd.read_csv(r'C:\\Users\\AKANSHA\\Downloads\\RPL.csv')\n",
    "rpl.columns\n",
    "#removing unwanted column from the dataset\n",
    "rpl.drop('RowNumber', axis=1, inplace=True)\n",
    "rpl.drop('CustomerId', axis=1, inplace=True)\n",
    "rpl.drop('Surname', axis=1, inplace=True)\n",
    "rpl.drop('Geography', axis=1, inplace=True)\n",
    "rpl.drop('Gender', axis=1, inplace=True)\n",
    "rpl.columns\n",
    "\n",
    "rpl.isna().sum() # there are no NA value in the dataset\n",
    "print(rpl)\n",
    "rpl.dtypes\n",
    "# splitting data into training and test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "y = rpl.Exited\n",
    "x = rpl.drop('Exited', axis=1 )\n",
    "X_train, X_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Separating the data set into 2 parts - all the inputs and label columns\n",
    "# converting the integer type into float32 format \n",
    "x_train = forest.iloc[:,1:].values.astype(\"float32\")\n",
    "x_test = forest.iloc[:,1:].values.astype(\"float32\")\n",
    "y_train = forest.area.values.astype(\"float32\")\n",
    "y_test = forest.area.values.astype(\"float32\")\n",
    "\n",
    "# Normalizing the inputs to fall under 0-1 by \n",
    "# diving the entire data with 255 (max pixel value)\n",
    "x_train = x_train/255\n",
    "x_test = x_test/255\n",
    "\n",
    "# one hot encoding outputs for both train and test data sets \n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "# Storing the number of classes into the variable num_of_classes \n",
    "num_of_classes = y_test.shape[1]\n",
    "x_train.shape\n",
    "y_train.shape\n",
    "x_test.shape\n",
    "y_test.shape\n",
    "\n",
    "# Creating a user defined function to return the model for which we are\n",
    "# giving the input to train the ANN mode\n",
    "def design_mlp():\n",
    "    # Initializing the model \n",
    "    model = Sequential()\n",
    "    model.add(Dense(150,input_dim =9,activation=\"relu\"))\n",
    "    model.add(Dense(200,activation=\"tanh\"))\n",
    "    model.add(Dense(100,activation=\"tanh\"))\n",
    "    model.add(Dense(500,activation=\"tanh\"))\n",
    "    model.add(Dense(num_of_classes,activation=\"softmax\"))\n",
    "    model.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "# building a cnn model using train data set and validating on test data set\n",
    "model = design_mlp()\n",
    "\n",
    "# fitting model on train data\n",
    "model.fit(x=x_train,y=y_train,batch_size=1000,epochs=20)\n",
    "\n",
    "# Evaluating the model on test data  \n",
    "eval_score_test = model.evaluate(x_test,y_test,verbose = 1)\n",
    "print (\"Accuracy: %.3f%%\" %(eval_score_test[1]*100)) \n",
    "# accuracy on test data set\n",
    "# accuracy score on train data \n",
    "eval_score_train = model.evaluate(x_train,y_train,verbose=0)\n",
    "print (\"Accuracy: %.3f%%\" %(eval_score_train[1]*100)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
