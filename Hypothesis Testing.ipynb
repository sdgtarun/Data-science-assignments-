{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "834dbe32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Unit A  Unit B\n",
      "0   6.8090  6.7703\n",
      "1   6.4376  7.5093\n",
      "2   6.9157  6.7300\n",
      "3   7.3012  6.7878\n",
      "4   7.4488  7.1522\n",
      "5   7.3871  6.8110\n",
      "6   6.8755  7.2212\n",
      "7   7.0621  6.6606\n",
      "8   6.6840  7.2402\n",
      "9   6.8236  7.0503\n",
      "10  7.3930  6.8810\n",
      "11  7.5169  7.4059\n",
      "12  6.9246  6.7652\n",
      "13  6.9256  6.0380\n",
      "14  6.5797  7.1581\n",
      "15  6.8394  7.0240\n",
      "16  6.5970  6.6672\n",
      "17  7.2705  7.4314\n",
      "18  7.2828  7.3070\n",
      "19  7.3495  6.7478\n",
      "20  6.9438  6.8889\n",
      "21  7.1560  7.4220\n",
      "22  6.5341  6.5217\n",
      "23  7.2854  7.1688\n",
      "24  6.9952  6.7594\n",
      "25  6.8568  6.9399\n",
      "26  7.2163  7.0133\n",
      "27  6.6801  6.9182\n",
      "28  6.9431  6.3346\n",
      "29  7.0852  7.5459\n",
      "30  6.7794  7.0992\n",
      "31  7.2783  7.1180\n",
      "32  7.1561  6.6965\n",
      "33  7.3943  6.5780\n",
      "34  6.9405  7.3875\n",
      "35     NaN     NaN\n",
      "36     NaN     NaN\n",
      "37     NaN     NaN\n",
      "38     NaN     NaN\n",
      "39     NaN     NaN\n",
      "40     NaN     NaN\n",
      "41     NaN     NaN\n",
      "42     NaN     NaN\n",
      "43     NaN     NaN\n",
      "44     NaN     NaN\n",
      "45     NaN     NaN\n",
      "46     NaN     NaN\n",
      "47     NaN     NaN\n",
      "48     NaN     NaN\n",
      "49     NaN     NaN\n",
      "50     NaN     NaN\n",
      "Help on function levene in module scipy.stats.morestats:\n",
      "\n",
      "levene(*args, center='median', proportiontocut=0.05)\n",
      "    Perform Levene test for equal variances.\n",
      "    \n",
      "    The Levene test tests the null hypothesis that all input samples\n",
      "    are from populations with equal variances.  Levene's test is an\n",
      "    alternative to Bartlett's test `bartlett` in the case where\n",
      "    there are significant deviations from normality.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    sample1, sample2, ... : array_like\n",
      "        The sample data, possibly with different lengths. Only one-dimensional\n",
      "        samples are accepted.\n",
      "    center : {'mean', 'median', 'trimmed'}, optional\n",
      "        Which function of the data to use in the test.  The default\n",
      "        is 'median'.\n",
      "    proportiontocut : float, optional\n",
      "        When `center` is 'trimmed', this gives the proportion of data points\n",
      "        to cut from each end. (See `scipy.stats.trim_mean`.)\n",
      "        Default is 0.05.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    statistic : float\n",
      "        The test statistic.\n",
      "    pvalue : float\n",
      "        The p-value for the test.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    Three variations of Levene's test are possible.  The possibilities\n",
      "    and their recommended usages are:\n",
      "    \n",
      "      * 'median' : Recommended for skewed (non-normal) distributions>\n",
      "      * 'mean' : Recommended for symmetric, moderate-tailed distributions.\n",
      "      * 'trimmed' : Recommended for heavy-tailed distributions.\n",
      "    \n",
      "    The test version using the mean was proposed in the original article\n",
      "    of Levene ([2]_) while the median and trimmed mean have been studied by\n",
      "    Brown and Forsythe ([3]_), sometimes also referred to as Brown-Forsythe\n",
      "    test.\n",
      "    \n",
      "    References\n",
      "    ----------\n",
      "    .. [1] https://www.itl.nist.gov/div898/handbook/eda/section3/eda35a.htm\n",
      "    .. [2] Levene, H. (1960). In Contributions to Probability and Statistics:\n",
      "           Essays in Honor of Harold Hotelling, I. Olkin et al. eds.,\n",
      "           Stanford University Press, pp. 278-292.\n",
      "    .. [3] Brown, M. B. and Forsythe, A. B. (1974), Journal of the American\n",
      "           Statistical Association, 69, 364-367\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    Test whether or not the lists `a`, `b` and `c` come from populations\n",
      "    with equal variances.\n",
      "    \n",
      "    >>> from scipy.stats import levene\n",
      "    >>> a = [8.88, 9.12, 9.04, 8.98, 9.00, 9.08, 9.01, 8.85, 9.06, 8.99]\n",
      "    >>> b = [8.88, 8.95, 9.29, 9.44, 9.15, 9.58, 8.36, 9.18, 8.67, 9.05]\n",
      "    >>> c = [8.95, 9.12, 8.95, 8.85, 9.03, 8.84, 9.07, 8.98, 8.86, 8.98]\n",
      "    >>> stat, p = levene(a, b, c)\n",
      "    >>> p\n",
      "    0.002431505967249681\n",
      "    \n",
      "    The small p-value suggests that the populations do not have equal\n",
      "    variances.\n",
      "    \n",
      "    This is not surprising, given that the sample variance of `b` is much\n",
      "    larger than that of `a` and `c`:\n",
      "    \n",
      "    >>> [np.var(x, ddof=1) for x in [a, b, c]]\n",
      "    [0.007054444444444413, 0.13073888888888888, 0.008890000000000002]\n",
      "\n",
      "Help on function ttest_ind in module scipy.stats.stats:\n",
      "\n",
      "ttest_ind(a, b, axis=0, equal_var=True, nan_policy='propagate', permutations=None, random_state=None, alternative='two-sided', trim=0)\n",
      "    Calculate the T-test for the means of *two independent* samples of scores.\n",
      "    \n",
      "    This is a two-sided test for the null hypothesis that 2 independent samples\n",
      "    have identical average (expected) values. This test assumes that the\n",
      "    populations have identical variances by default.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    a, b : array_like\n",
      "        The arrays must have the same shape, except in the dimension\n",
      "        corresponding to `axis` (the first, by default).\n",
      "    axis : int or None, optional\n",
      "        Axis along which to compute test. If None, compute over the whole\n",
      "        arrays, `a`, and `b`.\n",
      "    equal_var : bool, optional\n",
      "        If True (default), perform a standard independent 2 sample test\n",
      "        that assumes equal population variances [1]_.\n",
      "        If False, perform Welch's t-test, which does not assume equal\n",
      "        population variance [2]_.\n",
      "    \n",
      "        .. versionadded:: 0.11.0\n",
      "    \n",
      "    nan_policy : {'propagate', 'raise', 'omit'}, optional\n",
      "        Defines how to handle when input contains nan.\n",
      "        The following options are available (default is 'propagate'):\n",
      "    \n",
      "          * 'propagate': returns nan\n",
      "          * 'raise': throws an error\n",
      "          * 'omit': performs the calculations ignoring nan values\n",
      "    \n",
      "        The 'omit' option is not currently available for permutation tests or\n",
      "        one-sided asympyotic tests.\n",
      "    \n",
      "    permutations : non-negative int, np.inf, or None (default), optional\n",
      "        If 0 or None (default), use the t-distribution to calculate p-values.\n",
      "        Otherwise, `permutations` is  the number of random permutations that\n",
      "        will be used to estimate p-values using a permutation test. If\n",
      "        `permutations` equals or exceeds the number of distinct partitions of\n",
      "        the pooled data, an exact test is performed instead (i.e. each\n",
      "        distinct partition is used exactly once). See Notes for details.\n",
      "    \n",
      "        .. versionadded:: 1.7.0\n",
      "    \n",
      "    random_state : {None, int, `numpy.random.Generator`,\n",
      "            `numpy.random.RandomState`}, optional\n",
      "    \n",
      "        If `seed` is None (or `np.random`), the `numpy.random.RandomState`\n",
      "        singleton is used.\n",
      "        If `seed` is an int, a new ``RandomState`` instance is used,\n",
      "        seeded with `seed`.\n",
      "        If `seed` is already a ``Generator`` or ``RandomState`` instance then\n",
      "        that instance is used.\n",
      "    \n",
      "        Pseudorandom number generator state used to generate permutations\n",
      "        (used only when `permutations` is not None).\n",
      "    \n",
      "        .. versionadded:: 1.7.0\n",
      "    \n",
      "    alternative : {'two-sided', 'less', 'greater'}, optional\n",
      "        Defines the alternative hypothesis.\n",
      "        The following options are available (default is 'two-sided'):\n",
      "    \n",
      "          * 'two-sided'\n",
      "          * 'less': one-sided\n",
      "          * 'greater': one-sided\n",
      "    \n",
      "        .. versionadded:: 1.6.0\n",
      "    \n",
      "    trim : float, optional\n",
      "        If nonzero, performs a trimmed (Yuen's) t-test.\n",
      "        Defines the fraction of elements to be trimmed from each end of the\n",
      "        input samples. If 0 (default), no elements will be trimmed from either\n",
      "        side. The number of trimmed elements from each tail is the floor of the\n",
      "        trim times the number of elements. Valid range is [0, .5).\n",
      "    \n",
      "        .. versionadded:: 1.7\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    statistic : float or array\n",
      "        The calculated t-statistic.\n",
      "    pvalue : float or array\n",
      "        The two-tailed p-value.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    Suppose we observe two independent samples, e.g. flower petal lengths, and\n",
      "    we are considering whether the two samples were drawn from the same\n",
      "    population (e.g. the same species of flower or two species with similar\n",
      "    petal characteristics) or two different populations.\n",
      "    \n",
      "    The t-test quantifies the difference between the arithmetic means\n",
      "    of the two samples. The p-value quantifies the probability of observing\n",
      "    as or more extreme values assuming the null hypothesis, that the\n",
      "    samples are drawn from populations with the same population means, is true.\n",
      "    A p-value larger than a chosen threshold (e.g. 5% or 1%) indicates that\n",
      "    our observation is not so unlikely to have occurred by chance. Therefore,\n",
      "    we do not reject the null hypothesis of equal population means.\n",
      "    If the p-value is smaller than our threshold, then we have evidence\n",
      "    against the null hypothesis of equal population means.\n",
      "    \n",
      "    By default, the p-value is determined by comparing the t-statistic of the\n",
      "    observed data against a theoretical t-distribution.\n",
      "    When ``1 < permutations < binom(n, k)``, where\n",
      "    \n",
      "    * ``k`` is the number of observations in `a`,\n",
      "    * ``n`` is the total number of observations in `a` and `b`, and\n",
      "    * ``binom(n, k)`` is the binomial coefficient (``n`` choose ``k``),\n",
      "    \n",
      "    the data are pooled (concatenated), randomly assigned to either group `a`\n",
      "    or `b`, and the t-statistic is calculated. This process is performed\n",
      "    repeatedly (`permutation` times), generating a distribution of the\n",
      "    t-statistic under the null hypothesis, and the t-statistic of the observed\n",
      "    data is compared to this distribution to determine the p-value. When\n",
      "    ``permutations >= binom(n, k)``, an exact test is performed: the data are\n",
      "    partitioned between the groups in each distinct way exactly once.\n",
      "    \n",
      "    The permutation test can be computationally expensive and not necessarily\n",
      "    more accurate than the analytical test, but it does not make strong\n",
      "    assumptions about the shape of the underlying distribution.\n",
      "    \n",
      "    Use of trimming is commonly referred to as the trimmed t-test. At times\n",
      "    called Yuen's t-test, this is an extension of Welch's t-test, with the\n",
      "    difference being the use of winsorized means in calculation of the variance\n",
      "    and the trimmed sample size in calculation of the statistic. Trimming is\n",
      "    reccomended if the underlying distribution is long-tailed or contaminated\n",
      "    with outliers [4]_.\n",
      "    \n",
      "    References\n",
      "    ----------\n",
      "    .. [1] https://en.wikipedia.org/wiki/T-test#Independent_two-sample_t-test\n",
      "    \n",
      "    .. [2] https://en.wikipedia.org/wiki/Welch%27s_t-test\n",
      "    \n",
      "    .. [3] http://en.wikipedia.org/wiki/Resampling_%28statistics%29\n",
      "    \n",
      "    .. [4] Yuen, Karen K. \"The Two-Sample Trimmed t for Unequal Population\n",
      "           Variances.\" Biometrika, vol. 61, no. 1, 1974, pp. 165-170. JSTOR,\n",
      "           www.jstor.org/stable/2334299. Accessed 30 Mar. 2021.\n",
      "    \n",
      "    .. [5] Yuen, Karen K., and W. J. Dixon. \"The Approximate Behaviour and\n",
      "           Performance of the Two-Sample Trimmed t.\" Biometrika, vol. 60,\n",
      "           no. 2, 1973, pp. 369-374. JSTOR, www.jstor.org/stable/2334550.\n",
      "           Accessed 30 Mar. 2021.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> from scipy import stats\n",
      "    >>> rng = np.random.default_rng()\n",
      "    \n",
      "    Test with sample with identical means:\n",
      "    \n",
      "    >>> rvs1 = stats.norm.rvs(loc=5, scale=10, size=500, random_state=rng)\n",
      "    >>> rvs2 = stats.norm.rvs(loc=5, scale=10, size=500, random_state=rng)\n",
      "    >>> stats.ttest_ind(rvs1, rvs2)\n",
      "    Ttest_indResult(statistic=-0.4390847099199348, pvalue=0.6606952038870015)\n",
      "    >>> stats.ttest_ind(rvs1, rvs2, equal_var=False)\n",
      "    Ttest_indResult(statistic=-0.4390847099199348, pvalue=0.6606952553131064)\n",
      "    \n",
      "    `ttest_ind` underestimates p for unequal variances:\n",
      "    \n",
      "    >>> rvs3 = stats.norm.rvs(loc=5, scale=20, size=500, random_state=rng)\n",
      "    >>> stats.ttest_ind(rvs1, rvs3)\n",
      "    Ttest_indResult(statistic=-1.6370984482905417, pvalue=0.1019251574705033)\n",
      "    >>> stats.ttest_ind(rvs1, rvs3, equal_var=False)\n",
      "    Ttest_indResult(statistic=-1.637098448290542, pvalue=0.10202110497954867)\n",
      "    \n",
      "    When ``n1 != n2``, the equal variance t-statistic is no longer equal to the\n",
      "    unequal variance t-statistic:\n",
      "    \n",
      "    >>> rvs4 = stats.norm.rvs(loc=5, scale=20, size=100, random_state=rng)\n",
      "    >>> stats.ttest_ind(rvs1, rvs4)\n",
      "    Ttest_indResult(statistic=-1.9481646859513422, pvalue=0.05186270935842703)\n",
      "    >>> stats.ttest_ind(rvs1, rvs4, equal_var=False)\n",
      "    Ttest_indResult(statistic=-1.3146566100751664, pvalue=0.1913495266513811)\n",
      "    \n",
      "    T-test with different means, variance, and n:\n",
      "    \n",
      "    >>> rvs5 = stats.norm.rvs(loc=8, scale=20, size=100, random_state=rng)\n",
      "    >>> stats.ttest_ind(rvs1, rvs5)\n",
      "    Ttest_indResult(statistic=-2.8415950600298774, pvalue=0.0046418707568707885)\n",
      "    >>> stats.ttest_ind(rvs1, rvs5, equal_var=False)\n",
      "    Ttest_indResult(statistic=-1.8686598649188084, pvalue=0.06434714193919686)\n",
      "    \n",
      "    When performing a permutation test, more permutations typically yields\n",
      "    more accurate results. Use a ``np.random.Generator`` to ensure\n",
      "    reproducibility:\n",
      "    \n",
      "    >>> stats.ttest_ind(rvs1, rvs5, permutations=10000,\n",
      "    ...                 random_state=rng)\n",
      "    Ttest_indResult(statistic=-2.8415950600298774, pvalue=0.0052)\n",
      "    \n",
      "    Take these two samples, one of which has an extreme tail.\n",
      "    \n",
      "    >>> a = (56, 128.6, 12, 123.8, 64.34, 78, 763.3)\n",
      "    >>> b = (1.1, 2.9, 4.2)\n",
      "    \n",
      "    Use the `trim` keyword to perform a trimmed (Yuen) t-test. For example,\n",
      "    using 20% trimming, ``trim=.2``, the test will reduce the impact of one\n",
      "    (``np.floor(trim*len(a))``) element from each tail of sample `a`. It will\n",
      "    have no effect on sample `b` because ``np.floor(trim*len(b))`` is 0.\n",
      "    \n",
      "    >>> stats.ttest_ind(a, b, trim=.2)\n",
      "    Ttest_indResult(statistic=3.4463884028073513,\n",
      "                    pvalue=0.01369338726499547)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tarun\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:5039: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(\n"
     ]
    }
   ],
   "source": [
    "#Hypothesis Testing Exercises (Module - 5)\n",
    "#1.) A F&B manager wants to determine whether there is any significant difference in the diameter of the cutlet between two units. A randomly selected sample of cutlets was collected from both units and measured? Analyze the data and draw inferences at 5% significance level. Please state the assumptions and tests that you carried out to check validity of the assumptions.\n",
    "#Answer;-\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from scipy import stats\n",
    "cutlets = pd.read_csv(r'C:\\Users\\tarun\\Documents\\taruns imp\\Data science material\\assignments\\SETS\\Hypothesis Testing Exercises\\Cutlets.csv')\n",
    "print(cutlets) \n",
    "# Business Problem: there is any significant difference in the diameter of the cutlet between two units\n",
    "# Ho: unit.A = unit.B  --> no action\n",
    "# Ha: unit.a != unit.B    --> take action\n",
    "#EDA \n",
    "cutlets.isna().sum()  # there are na value in the data\n",
    "data = cutlets.dropna(how = 'all') # creating another dataset without NA value \n",
    "data.columns\n",
    "# Normality test\n",
    "# Ho: Data are normal\n",
    "# Ha: Data are not normal --> take action = transformation\n",
    "\n",
    "data.rename(columns= {'Unit A':'unitA', 'Unit B' : 'unitB' },inplace=True)\n",
    "data.columns\n",
    "stats.shapiro(data.unitA)\n",
    "#p-value=0.31998>0.05(alpha=5%)\n",
    "#p-high Ho fly -> fail to reject Ho\n",
    "stats.shapiro(data.unitB)\n",
    "#p-value=0.52249>0.05(alpha=5%)\n",
    "#p high Ho fly -> fail to reject Ho\n",
    "# Variance test\n",
    "scipy.stats.levene(data.unitA,data.unitB)\n",
    "help(scipy.stats.levene)\n",
    "# p-value = 0.4176 > 0.05 so p high null fly => Equal variances\n",
    "# 2 Sample T test\n",
    "scipy.stats.ttest_ind(data.unitA,data.unitB)\n",
    "help(scipy.stats.ttest_ind)\n",
    "#p-value=0.472239 > 0.05 so p high null fly\n",
    "\n",
    "# Conclusion: \n",
    "#There is significant difference in the diameter of the cutlet between two units\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b81d0291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Laboratory_1  Laboratory_2  Laboratory_3  Laboratory_4\n",
      "0          185.35        165.53        176.70        166.13\n",
      "1          170.49        185.91        198.45        160.79\n",
      "2          192.77        194.92        201.23        185.18\n",
      "3          177.33        183.00        199.61        176.42\n",
      "4          193.41        169.57        204.63        152.60\n",
      "..            ...           ...           ...           ...\n",
      "115        160.25        170.66        193.80        172.68\n",
      "116        176.08        183.98        215.25        177.64\n",
      "117        202.48        174.54        211.22        170.27\n",
      "118        182.40        197.18        194.52        150.87\n",
      "119        182.09        215.17        221.49        162.21\n",
      "\n",
      "[120 rows x 4 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.143740909435053e-58"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2.) A hospital wants to determine whether there is any difference in the average Turn Around Time (TAT) of reports of the laboratories on their preferred list. They collected a random sample and recorded TAT for reports of 4 laboratories. TAT is defined as sample collected to report dispatch.\n",
    "#Analyze the data and determine whether there is any difference in average TAT among the different laboratories at 5% significance level.\n",
    "#answer ;-\n",
    "lab = pd.read_csv(r'C:\\Users\\tarun\\Documents\\taruns imp\\Data science material\\assignments\\SETS\\Hypothesis Testing Exercises\\lab_tat_updated.csv')\n",
    "print(lab)\n",
    "# Business Problem: difference in the average Turn Around Time (TAT) of reports of the laboratories\n",
    "# Ho: turn around time = laboratories list  --> no action\n",
    "# Ha: turn around time  != laboratories list    --> take action\n",
    "#EDA on the dataset\n",
    "lab.isna().sum() # there are no NA value \n",
    "lab.columns\n",
    "# Normality test\n",
    "# Ho: Data are normal\n",
    "# Ha: Data are not normal --> take action = transformation\n",
    "stats.shapiro(lab.Laboratory_1)\n",
    "# p-value = 0.42317 > 0.05 so p high null fly => It follows normal distribution\n",
    "stats.shapiro(lab.Laboratory_2)\n",
    "# p-value = 0.8637 > 0.05 so p high null fly => It follows normal distribution\n",
    "stats.shapiro(lab.Laboratory_3)\n",
    "# p-value = 0.06547 > 0.05 so p high null fly => It follows normal distribution\n",
    "stats.shapiro(lab.Laboratory_4)\n",
    "# p-value = 0.6619 > 0.05 so p high null fly => It follows normal distribution\n",
    "# Variance test\n",
    "scipy.stats.levene(lab.Laboratory_1,lab.Laboratory_2,lab.Laboratory_3,lab.Laboratory_4)\n",
    "\n",
    "# One - Way Anova\n",
    "F,p = stats.f_oneway(lab.Laboratory_1,lab.Laboratory_2,lab.Laboratory_3,lab.Laboratory_4)\n",
    "p\n",
    "#conclusion:\n",
    "#p-value is high than 0.05 value so there is no difference in the average Turn Around Time (TAT) of reports of the laboratories on their preferred list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc69a2dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Observed Values  East  West  North  South\n",
      "0           Males    50   142    131     70\n",
      "1         Females   435  1523   1356    750\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'West'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17120/2603661318.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0mchi_pValue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mChisquares_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mcount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcrosstab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSouth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[0mChisquares_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchi2_contingency\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcorrection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[0mchi_pValue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mChisquares_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5485\u001b[0m         ):\n\u001b[0;32m   5486\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5487\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5488\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5489\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'West'"
     ]
    }
   ],
   "source": [
    "#3.) Sales of products in four different regions is tabulated for males and females. Find if male-female buyer rations are similar across regions.\n",
    "#Answer;- \n",
    "buyer = pd.read_csv(r'C:\\Users\\tarun\\Documents\\taruns imp\\Data science material\\assignments\\SETS\\Hypothesis Testing Exercises\\BuyerRatio.csv') \n",
    "print(buyer)\n",
    "\n",
    "# Business Problem: male-female buyer rations are similar across regions\n",
    "# Ho: male buyer rations = female buyer rations  --> no action\n",
    "# Ha: male buyer rations != female buyer rations   --> take action\n",
    "#EDA on the dataset\n",
    "buyer.isna().sum()\n",
    "buyer.columns\n",
    "# Ho: Data are normal\n",
    "# Ha: Data are not normal --> take action = transformation\n",
    "# chisq.test \n",
    "import scipy\n",
    "count = pd.crosstab(buyer.East,buyer.West)\n",
    "Chisquares_results = scipy.stats.chi2_contingency(count,correction = False)\n",
    "Chi_pValue = Chisquares_results[1]\n",
    "\n",
    "count = pd.crosstab(buyer.North,buyer.South)\n",
    "Chisquares_results = scipy.stats.chi2_contingency(count, correction = False)\n",
    "chi_pValue = Chisquares_results[1]\n",
    "\n",
    "count = pd.crosstab(buyer.East,buyer.North)\n",
    "Chisquares_results = scipy.stats.chi2_contingency(count,correction=False)\n",
    "chi_pValue = Chisquares_results[1]\n",
    "\n",
    "count = pd.crosstab(count.West,count.South)\n",
    "Chisquares_results = scipy.stats.chi2_contingency(count,correction=False)\n",
    "chi_pValue = Chisquares_results[1]\n",
    "# p-value > 0.05 which conlcude male buyer rations = female buyer rations \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08682289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Test Statistic', 'p-value'], [0.0, 1.0]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Telecall uses 4 centers around the globe to process customer order forms. They audit a certain % of the customer order forms. Any error in order form renders it defective and must be reworked before processing. The manager wants to check whether the defective % varies by center. Please analyze the data at 5% significance level and help the manager draw appropriate inferences\n",
    "#answer;-\n",
    "customer = pd.read_csv(r'C:\\Users\\tarun\\Documents\\taruns imp\\Data science material\\assignments\\SETS\\Hypothesis Testing Exercises\\CustomerOrderform.csv')\n",
    "customer.columns\n",
    "# we have discret dataset so need to perform chi-squared test \n",
    "# Business Problem: whether the defective % varies by center\n",
    "# Ho: defecive % = 4 centers  --> no action\n",
    "# Ha: defective % != 4 centers   --> take action\n",
    "#EDA on the dataset\n",
    "customer.isna().sum()\n",
    "data = customer.dropna(how= 'all')\n",
    "data.columns\n",
    "# Ho: Data are normal\n",
    "# Ha: Data are not normal --> take action = transformation\n",
    "# chisq.test \n",
    "import scipy\n",
    "df = data['Phillippines'].value_counts()\n",
    "Chisquares_results = scipy.stats.chi2_contingency(df)\n",
    "Chi_square = [['Test Statistic', 'p-value'], [Chisquares_results[0], Chisquares_results[1]]]\n",
    "Chi_square\n",
    "\n",
    "\n",
    "df = data [\"Indonesia\"].value_counts()\n",
    "Chisquares_results = scipy.stats.chi2_contingency(df)\n",
    "Chi_square = [['Test Statistic', 'p-value'], [Chisquares_results[0], Chisquares_results[1]]]\n",
    "Chi_square\n",
    "\n",
    "df = data [\"Malta\"].value_counts()\n",
    "Chisquares_results = scipy.stats.chi2_contingency(df)\n",
    "Chi_square = [['Test Statistic', 'p-value'], [Chisquares_results[0], Chisquares_results[1]]]\n",
    "Chi_square\n",
    "\n",
    "df = data[\"India\"].value_counts()\n",
    "Chisquares_results = scipy.stats.chi2_contingency(df)\n",
    "Chi_square = [['Test Statistic', 'p-value'], [Chisquares_results[0], Chisquares_results[1]]]\n",
    "Chi_square\n",
    "# p-value > 0.05 hence the defective % is not equal in all the 4 centers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1213fa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Test Statistic', 'p-value'], [0.0, 1.0]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#5.) Fantaloons Sales managers commented that % of males versus females walking into the store differ based on day of the week. Analyze the data and determine whether there is evidence at 5 % significance level to support this hypothesis.\n",
    "#Answer;-\n",
    "fantaloons  = pd.read_csv(r'C:\\Users\\tarun\\Documents\\taruns imp\\Data science material\\assignments\\SETS\\Hypothesis Testing Exercises\\Fantaloons.csv')\n",
    "fantaloons.columns\n",
    "# we have discret dataset so need to perform chi-squared test\n",
    "# Business Problem: % of males versus females walking into the store differ based on day of the week\n",
    "# Ho: male and female % weekdays = male and female % weekend  --> no action\n",
    "# Ha: male and female % weekdays != male and female % weekend  --> take action\n",
    "#EDA on the dataset\n",
    "fantaloons.isna().sum()\n",
    "data = fantaloons.dropna(how= 'all')\n",
    "data.columns\n",
    "# Ho: Data are normal\n",
    "# Ha: Data are not normal --> take action = transformation\n",
    "# chisq.test \n",
    "import scipy\n",
    "df = data['Weekdays'].value_counts()\n",
    "Chisquares_results = scipy.stats.chi2_contingency(df)\n",
    "Chi_square = [['Test Statistic', 'p-value'], [Chisquares_results[0], Chisquares_results[1]]]\n",
    "Chi_square\n",
    "\n",
    "\n",
    "df = data [\"Weekend\"].value_counts()\n",
    "Chisquares_results = scipy.stats.chi2_contingency(df)\n",
    "Chi_square = [['Test Statistic', 'p-value'], [Chisquares_results[0], Chisquares_results[1]]]\n",
    "Chi_square\n",
    "#p-vale<0.05 which conclude the male and female % walking into the store is not equal on weekdays and weekend\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d109e579",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
